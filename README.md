# Car Price Prediction Using LGBMRegressor

## Table of Contents
- [Overview](#overview)
- [Dataset](#dataset)
- [Intuition Behind the Code](#intuition-behind-the-code)
- [Model](#model)
- [Installation](#installation)
- [Usage](#usage)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)

---

## Overview
This project aims to predict car prices using the **LightGBM Regression** model (`LGBMRegressor`). The dataset includes various features such as **make, model, year, mileage**, and more, which are used to train a regression model capable of accurately predicting car prices.

### Objectives:
- Build a robust predictive model for car prices.
- Use **LGBMRegressor**, a gradient boosting model, known for its speed and performance with large datasets.
- Apply advanced feature engineering to enhance model performance.
- Optimize the model using **Optuna** to minimize **RMSE**.

---

## Dataset
The dataset used for this project contains information about car sales, including features like:
Dataset
Input Files

The dataset used for this project contains information about cars, with features like:

   - id: A unique identifier for each car (Integer).
   - brand: The make of the car (Categorical).
   - model: The model of the car (Categorical).
   - model_year: The year of the car model (Integer).
   - milage: The total distance the car has traveled in miles (Integer).
   - fuel_type: The type of fuel the car uses, such as Gasoline or Diesel (Categorical).
   - engine: A string combining the engine's horsepower and size (String). It can be further processed to extract numerical values for Horsepower and Engine Size.
   - transmission: The type of transmission, such as Automatic or Manual (Categorical).
   - ext_col: Exterior color of the car (Categorical).
   - int_col: Interior color of the car (Categorical).
   - accident: Accident history, whether "None reported" or "At least 1 accident" (Categorical).
   - clean_title: Whether the car has a clean title or not (Categorical).
   - price: The price of the car (Integer). This is the target variable for prediction.

Output File

The output file contains two columns:

   - id: The same unique identifier for each car (from the input).
   - predicted_price: The predicted price of the car, generated by the model.

File Handling

Ensure that the following input files are available:

   = train.csv: Training data including the car features and target price.
   = test.csv: Test data containing car features for which the price will be predicted.
   = used_cars.csv: Additional data for car pricing that can be merged with the training data.
   = sample_submission.csv: A template file for the final submission, showing the format for the id and predicted_price columns.

You can download the dataset from https://www.kaggle.com/datasets/taeefnajib/used-car-price-prediction-dataset or use your own.

---

## Intuition Behind the Code

### 1. Data Visualization and Observation
The first step involves **visualizing the dataset** to identify patterns and relationships between features. Key insights include:
- **Horsepower** and **Price** are positively correlated.
- **Vehicle Age**, **Mileage per Year**, and **Power to Weight Ratio** show significant relationships with car price.
- I visualize missing data and check categorical distributions like **brand**, **fuel type**, and **transmission** types to understand the dataset.

### 2. Feature Engineering
After observing the data, I apply **feature engineering**:
- Calculating **Vehicle Age** from the model year.
- Creating **Mileage per Year** to measure car usage.
- Extracting **Horsepower** and **Engine Size** from the engine information.
- Calculating the **Power to Weight Ratio** for car performance.

I handle rare categories by replacing them with "noise" to improve model training.

### 3. Model Creation: Luxury vs Non-Luxury
I split the data into two categories:
- **Luxury Cars** (e.g., Mercedes-Benz, BMW, Audi).
- **Non-Luxury Cars** (e.g., Ford, Toyota).

This approach improves model accuracy by capturing the different pricing dynamics between the two car segments.

### 4. Model Training and Optimization
I use **Optuna** to fine-tune model parameters, running the optimization process until the **RMSE** is below a predefined threshold (e.g., **RMSE < Y**). This ensures that the model is both accurate and efficient.

---

## Model
This project uses the **LightGBM Regression Model (LGBMRegressor)**, which is an efficient and scalable gradient boosting model for regression tasks. I chose this model because:
- It handles large datasets well.
- It's highly efficient in terms of training speed and memory consumption.
- It supports both categorical and numerical features.

---

## Installation

### Install the Required Libraries

Run the following command in your terminal or command prompt to install the necessary Python libraries:

```bash
pip install numpy pandas seaborn scikit-learn lightgbm optuna tqdm tabulate colorama matplotlib seaborn


### Clone the Repository

To get started, clone the project repository to your local machine:

```bash
git clone [https://github.com/HaoYu2024/Car-Price-Perdiction-with-LGBM.git]
cd car-price-prediction
```

### Dataset

Ensure you have the dataset files (`train.csv`, `test.csv`, `used_cars.csv`, `sample_submission.csv`) in the working directory. These can either be downloaded from the provided source or obtained separately.

---

## Usage

### Preprocessing

Before training the model, the dataset undergoes preprocessing to handle categorical variables, missing values, and feature engineering. Some of the key preprocessing steps include:
- Handling missing data with `SimpleImputer`.
- Encoding categorical features using the `category` data type.
- Creating new features like **Vehicle Age**, **Mileage per Year**, **Horsepower**, and **Power to Weight Ratio**.

### Training the Model

To train the model, the script uses **LGBMRegressor** with optimized hyperparameters using **Optuna**. The project includes two separate models:
- One for **luxury cars**.
- Another for **non-luxury cars**.

The script performs K-Fold Cross-Validation and tunes the model's parameters using Optuna, saving the best parameters for future use.

To train and test the model, you can run the following command:

```bash
python hao_lgbm_5.py
```

This script will:
- Load and preprocess the data.
- Split the data into training and validation sets.
- Train the **LGBMRegressor** model using the best parameters.
- Perform predictions on the test data.
- Generate a submission CSV file with predicted prices.

---

## Results

### Metrics

After training, the model is evaluated using the following metrics:
- **Root Mean Squared Error (RMSE) 73299**
---
## Contributing

Contributions are welcome! If you'd like to improve the model, enhance feature engineering, or suggest new ideas, feel free to open a pull request or raise an issue.

---

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more information.

---

## Acknowledgements

Special thanks to the creators of the datasets and the developers behind **LightGBM**, **Optuna**, and **Scikit-learn** for providing excellent tools for machine learning. If you have any questions, feel free to reach out or consult the official documentation for each library:
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [Scikit-learn Documentation](https://scikit-learn.org/)

